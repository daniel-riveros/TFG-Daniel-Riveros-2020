{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN PERROS Y GATOS 95% PRECISIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo con un 95% de precisión para nuestro problema de perros y Gatos\n",
    "\n",
    "# Vamos a añadir varias funciones que nos van a ayudar a realizar diferentes estudios de resultados que necesitabamos hacer.\n",
    "\n",
    "# Para hacer funcionar el modelo y toda su estructura debemos tener instalado en nuestro entorno de anaconda la versión\n",
    "# 2.1.0 de tensorflow, nosotros hemos usado la versión para la gráfica :\n",
    "\n",
    "# conda install tensorflow-gpu==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Librerias necesarias para todo el proceso de entrenamiento\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import PIL\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.activations import linear\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para la generación de gráficas, debemos indicar el número de épocas que ha usado el modelo para generarla \n",
    "# ajustada a los datos dados.\n",
    "\n",
    "# Historial del entrenamiento, nombre con el que queremos guardar el modelo, número de épocas usadas.\n",
    "def Visualiza_Graficas(historial, nombre, numEpochs):\n",
    "    \n",
    "    # Ploteamos la gráfica de perdida\n",
    "    pyplot.figure(0)  \n",
    "    pyplot.plot(historial.history['loss'],'r')  \n",
    "    pyplot.plot(historial.history['val_loss'],'g')  \n",
    "    pyplot.xticks(np.arange(0, numEpochs+1, numEpochs/10))  \n",
    "    pyplot.rcParams['figure.figsize'] = (20, 20)  \n",
    "    pyplot.xlabel(\"Num of Epochs\")  \n",
    "    pyplot.ylabel(\"Loss\")  \n",
    "    pyplot.title(\"Training Loss vs Validation Loss\")  \n",
    "    pyplot.legend(['train','validation'])\n",
    "    pyplot.savefig('graficas/'+ nombre + '_plot1.png')\n",
    "    \n",
    "    # Ploteamos la gráfica de precisión precision\n",
    "    pyplot.figure(1)  \n",
    "    pyplot.plot(historial.history['accuracy'],'r')  \n",
    "    pyplot.plot(historial.history['val_accuracy'],'g')  \n",
    "    pyplot.xticks(np.arange(0, numEpochs+1, numEpochs/10))  \n",
    "    pyplot.rcParams['figure.figsize'] = (20, 20)  \n",
    "    pyplot.xlabel(\"Num of Epochs\")  \n",
    "    pyplot.ylabel(\"Accuracy\")  \n",
    "    pyplot.title(\"Training Accuracy vs Validation Accuracy\")  \n",
    "    pyplot.legend(['train','validation'])\n",
    "    pyplot.savefig('graficas/'+ nombre +'_plot2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo final usado, dos neuronas de salida con la función softmax\n",
    "def Genera_Modelo_Final():\n",
    "    # Capas de convolución\n",
    "    BASELAYERS = 16\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(BASELAYERS, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(AveragePooling2D((2, 2)))\n",
    "    model.add(Conv2D(2*BASELAYERS, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(AveragePooling2D((2, 2)))\n",
    "    model.add(Conv2D(4*BASELAYERS, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(AveragePooling2D((2, 2)))\n",
    "    model.add(Conv2D(8*BASELAYERS, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(AveragePooling2D((2, 2)))\n",
    "    model.add(Conv2D(16*BASELAYERS, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(AveragePooling2D((2, 2)))\n",
    "   \n",
    "    #Capas GAP y Dense\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # Compilación\n",
    "    opt= tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Limitación dinámica necesaria para las gráficas (A veces la memoria sobrepasa el límite y da error el entrenamiento)\n",
    "\n",
    "### Código obtenido de la propia página de TensorFlow ###\n",
    "### https://www.tensorflow.org/guide/gpu ###\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Deben aparecer las gráficas disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo desde la función creada anteriormente\n",
    "model = Genera_Modelo_Final()\n",
    "\n",
    "# Creamos el nombre con el que queremos guardar los datos\n",
    "nombre = 'Modelo_Final'\n",
    "\n",
    "# Creamos los callbacks para guardar en cada momento el mejor modelo obtenido y para parar el entrenamiento si se supera\n",
    "# un número indicado de épocas (patience) sin mejorar el resultado (de perdida en nuestro caso)\n",
    "Patience = 10\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=Patience),\n",
    "             ModelCheckpoint(filepath='best_model'+nombre, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "# Número de épocas máximas de entrenamiento\n",
    "Myepochs = 100;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18697 images belonging to 2 classes.\n",
      "Found 6303 images belonging to 2 classes.\n",
      "{'cats': 0, 'dogs': 1}\n",
      "{0: 'cats', 1: 'dogs'}\n"
     ]
    }
   ],
   "source": [
    "# Generamos los iteradores con las imagenes que obtenemos. Para poder usarlo debemos tener en la misma carpeta este\n",
    "# notebook y la carpeta que contiene el dataser \"new_dataset\"\n",
    "\n",
    "# Generador de datos de entrenamiento (Data Augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\n",
    "# Generador de datos de validación, no Data Augmentation\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "\n",
    "#Iteradores con generadores de datos diferentes.\n",
    "# IMPORTANTE: class_mode = 'categorical', indicamos a TF que queremos separar las clases.\n",
    "\n",
    "train_it = train_datagen.flow_from_directory('new_dataset/train/',\n",
    "    class_mode='categorical', batch_size=64, target_size=(224, 224))\n",
    "val_it = val_datagen.flow_from_directory('new_dataset/val/',\n",
    "    class_mode='categorical', batch_size=64, target_size=(224, 224))\n",
    "\n",
    "# Comprobamos que las clases están bien cogidas:\n",
    "labels = (train_it.class_indices)\n",
    "print(labels)\n",
    "\n",
    "# Damos la vuelta a las etiquetas, valor númerico --> valor texto\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo y lo evaluamos. Es posible que se pare por el callback, por ello es necesario mirar en que época\n",
    "# termina para generar una gráfica correcta con los datos.\n",
    "\n",
    "# Visualizamos la estructura del modelo\n",
    "model.summary();\n",
    "\n",
    "# Entrenamos el modelo\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "    validation_data=val_it, validation_steps=len(val_it), epochs=Myepochs, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "_, acc = model.evaluate(val_it, steps=len(val_it), verbose=1, callbacks=callbacks)\n",
    "print('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debemos poner el número de épocas usadas en el entrenamiento\n",
    "EpocasTotales = 64\n",
    "\n",
    "# Visualizamos las gráficas\n",
    "Visualiza_Graficas(history, nombre, EpocasTotales)\n",
    "\n",
    "# Guardamos el modelo (último generado, el mejor se ha ido guardando automáticamente por los callbacks)\n",
    "model.save('modelos/'+ nombre + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
